{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T14:31:02.701618Z",
     "start_time": "2021-02-09T14:31:01.931930Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:20.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare energy production dataset\n",
    "\n",
    "We used the bavaria energy production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T14:31:03.964708Z",
     "start_time": "2021-02-09T14:31:02.705144Z"
    }
   },
   "outputs": [],
   "source": [
    "# open the dataset\n",
    "co2_emissions = pd.read_excel('input/Bavaria_produced.xlsx')\n",
    "\n",
    "# convert the date to standard string format\n",
    "co2_emissions['Datum'] = co2_emissions['Datum'].str[-4:] + '-' + co2_emissions['Datum'].str[3:5] + '-' + co2_emissions['Datum'].str[:2]\n",
    "\n",
    "# transform the date to pandas datetime\n",
    "co2_emissions['Date'] = pd.to_datetime(co2_emissions.Datum + ' ' + co2_emissions.Uhrzeit +':00') \n",
    "\n",
    "# calculate the total kgCO2eq per hour\n",
    "co2_emissions['kgCO2eq'] = (\n",
    "    (co2_emissions['Biomasse[MWh]'] * 50.4) +\n",
    "    (co2_emissions['Wasserkraft[MWh]'] * 22.5) +\n",
    "    (co2_emissions['Wind Offshore[MWh]'] * 0.165) +\n",
    "    (co2_emissions['Wind Onshore[MWh]'] * 0.165) +\n",
    "    (co2_emissions['Photovoltaik[MWh]'] * 0.00448) +\n",
    "    (co2_emissions['Sonstige Erneuerbare[MWh]'] * 0.00664) +\n",
    "    (co2_emissions['Kernenergie[MWh]'] * 9.37) +\n",
    "    (co2_emissions['Braunkohle[MWh]'] * 1160) +\n",
    "    (co2_emissions['Steinkohle[MWh]'] * 1160) +\n",
    "    (co2_emissions['Erdgas[MWh]'] * 440) +\n",
    "    (co2_emissions['Sonstige Konventionelle[MWh]'] * 875) +\n",
    "    (co2_emissions['Pumpspeicher[MWh]'] * 958)\n",
    ")\n",
    "\n",
    "\n",
    "# Transform to kWh \n",
    "co2_emissions['TotalkWh'] = co2_emissions[['Biomasse[MWh]', 'Wasserkraft[MWh]',\n",
    "       'Wind Offshore[MWh]', 'Wind Onshore[MWh]', 'Photovoltaik[MWh]',\n",
    "       'Sonstige Erneuerbare[MWh]', 'Kernenergie[MWh]', 'Braunkohle[MWh]',\n",
    "       'Steinkohle[MWh]', 'Erdgas[MWh]', 'Pumpspeicher[MWh]',\n",
    "       'Sonstige Konventionelle[MWh]']].sum(1) * 1000\n",
    "\n",
    "\n",
    "# kgCO2eq per kWH\n",
    "co2_emissions['kgCO2eq/kWh'] = co2_emissions['kgCO2eq'] /co2_emissions['TotalkWh']\n",
    "\n",
    "\n",
    "# extract and rename the relevant columns\n",
    "co2_emissions = co2_emissions[\n",
    "    ['Date','Rens', 'NonRens', 'TotalkWh','kgCO2eq', 'kgCO2eq/kWh']].rename(columns = {'Date':'interval'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare mail days and mailed clients datasets\n",
    "\n",
    "The data is store in an Excel file in which different sheets contains a date with the client ids that were mailed. The file also contains the sheet (`alle Coder`) with the ids of all the clients of the company, and that were candidates of being mailed in a mail day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T14:31:04.153443Z",
     "start_time": "2021-02-09T14:31:03.967223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clients: 318\n"
     ]
    }
   ],
   "source": [
    "# read all the ids/codes\n",
    "codes = set(pd.read_excel('input/mails_coders.xls', sheet_name='alle Coder', header=None)[0])\n",
    "print(f\"Total clients: {len(codes)}\")\n",
    "\n",
    "# read the raw data were the information about the mails was kept\n",
    "dfs = pd.read_excel('input/mails_coders.xls', sheet_name=None)\n",
    "\n",
    "# list to keep the dataframe in each\n",
    "dfs_list = []\n",
    "\n",
    "# loop through the Excel sheets\n",
    "for key, df in dfs.items():\n",
    "    \n",
    "    # make sure that the name of the sheet contains a date in the format DDMMYYYY\n",
    "    if key.isnumeric() and len(key) == 8:\n",
    "        \n",
    "        # transform the date to the right string format\n",
    "        df['mailday'] = key[-4:] + '-' + key[2:4] + '-' + key[:2] + ' 00:00:00'\n",
    "        \n",
    "        # append to the list \n",
    "        dfs_list.append(df)\n",
    "\n",
    "# create the dataframe, and rename columns\n",
    "client_mails = pd.concat(dfs_list).rename(columns={\n",
    "    'Coder': 'client_id',\n",
    "    'mailday': '17h_day'\n",
    "})\n",
    "\n",
    "# all of the ones in this dataset were mailed\n",
    "client_mails['mailed'] = True\n",
    "\n",
    "# convert day to datetime\n",
    "client_mails['17h_day'] = pd.to_datetime(client_mails['17h_day'])\n",
    "\n",
    "# remove duplicates\n",
    "client_mails = client_mails.drop_duplicates(['client_id', '17h_day'])\n",
    "\n",
    "# create dataset that identifies maildays\n",
    "maildays = client_mails[['17h_day', 'mailed']].drop_duplicates().rename(columns={'mailed': 'mailday'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare charge events data source \n",
    "`greenweeks_charges.csv` contains the raw data obtain from the provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and clean the charge events\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T14:31:04.268291Z",
     "start_time": "2021-02-09T14:31:04.155851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics of the raw data:\n",
      "Total Charges (N): 270\n",
      "Total Clients: 91\n",
      "       Total charge amount       Total duration\n",
      "count               269.00               269.00\n",
      "mean               9384.35              5919.74\n",
      "std                8718.97              8383.75\n",
      "min                   0.00                 2.00\n",
      "25%                3308.00              1689.00\n",
      "50%                6510.00              4022.00\n",
      "75%               13488.00              7647.00\n",
      "max               38680.00             86456.00\n",
      "Summary statistics of the clean raw data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>charge_id</th>\n",
       "      <th>total_duration</th>\n",
       "      <th>meter_start</th>\n",
       "      <th>meter_end</th>\n",
       "      <th>total_charge</th>\n",
       "      <th>station_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>247.00</td>\n",
       "      <td>247.00</td>\n",
       "      <td>247.00</td>\n",
       "      <td>247.00</td>\n",
       "      <td>247.00</td>\n",
       "      <td>247.00</td>\n",
       "      <td>247.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7153.24</td>\n",
       "      <td>135.56</td>\n",
       "      <td>6409.71</td>\n",
       "      <td>532760.36</td>\n",
       "      <td>542980.10</td>\n",
       "      <td>10.22</td>\n",
       "      <td>15931.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>89.01</td>\n",
       "      <td>78.27</td>\n",
       "      <td>8566.43</td>\n",
       "      <td>1016667.97</td>\n",
       "      <td>1016942.88</td>\n",
       "      <td>8.62</td>\n",
       "      <td>34140.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7005.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>159.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>126.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>45.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7083.00</td>\n",
       "      <td>68.50</td>\n",
       "      <td>2186.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5519.00</td>\n",
       "      <td>3.93</td>\n",
       "      <td>889.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7159.00</td>\n",
       "      <td>135.00</td>\n",
       "      <td>4860.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13088.00</td>\n",
       "      <td>7.02</td>\n",
       "      <td>1102.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7238.00</td>\n",
       "      <td>202.50</td>\n",
       "      <td>8044.50</td>\n",
       "      <td>519075.00</td>\n",
       "      <td>525645.00</td>\n",
       "      <td>15.26</td>\n",
       "      <td>20681.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7317.00</td>\n",
       "      <td>269.00</td>\n",
       "      <td>86456.00</td>\n",
       "      <td>4090687.00</td>\n",
       "      <td>4098083.00</td>\n",
       "      <td>38.68</td>\n",
       "      <td>142039.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 client_id            charge_id       total_duration  \\\n",
       "count               247.00               247.00               247.00   \n",
       "mean               7153.24               135.56              6409.71   \n",
       "std                  89.01                78.27              8566.43   \n",
       "min                7005.00                 0.00               159.00   \n",
       "25%                7083.00                68.50              2186.50   \n",
       "50%                7159.00               135.00              4860.00   \n",
       "75%                7238.00               202.50              8044.50   \n",
       "max                7317.00               269.00             86456.00   \n",
       "\n",
       "               meter_start            meter_end         total_charge  \\\n",
       "count               247.00               247.00               247.00   \n",
       "mean             532760.36            542980.10                10.22   \n",
       "std             1016667.97           1016942.88                 8.62   \n",
       "min                   0.00               126.00                 0.13   \n",
       "25%                   0.00              5519.00                 3.93   \n",
       "50%                   0.00             13088.00                 7.02   \n",
       "75%              519075.00            525645.00                15.26   \n",
       "max             4090687.00           4098083.00                38.68   \n",
       "\n",
       "                station_id  \n",
       "count               247.00  \n",
       "mean              15931.31  \n",
       "std               34140.55  \n",
       "min                  45.00  \n",
       "25%                 889.00  \n",
       "50%                1102.00  \n",
       "75%               20681.00  \n",
       "max              142039.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the file\n",
    "charge_events = pd.read_csv('input/greenweeks_charges.csv')\n",
    "\n",
    "# print raw statistics\n",
    "print(\"Descriptive statistics of the raw data:\")\n",
    "print(f\"Total Charges (N): {len(charge_events)}\")\n",
    "print(f\"Total Clients: {len(charge_events.KundenID.unique())}\")\n",
    "print(charge_events[['Total charge amount','Total duration']].describe())\n",
    "\n",
    "# numerate rows by using the current index\n",
    "charge_events = charge_events.reset_index()\n",
    "\n",
    "# create a column map with new column names to simplify access to them\n",
    "colmap = {\n",
    "    'KundenID': 'client_id',\n",
    "    'index': 'charge_id',\n",
    "    'EVSE ID': 'ev_id',\n",
    "    'Start time': 'starttime',\n",
    "    'End time': 'endtime',\n",
    "    # Where does this come frome? Is it broken?\n",
    "    # 'Mailversand': 'mail',\n",
    "    'Total duration': 'total_duration',\n",
    "    'Meter start': 'meter_start', \n",
    "    'Meter end': 'meter_end', \n",
    "    'Total charge amount': 'total_charge',\n",
    "    'Charging station identifier': 'station_id',\n",
    "    'Charging station': 'station',\n",
    "    'Charging station serialnumber': 'station_sn',\n",
    "    'Charging station street': 'station_st',\n",
    "}\n",
    "\n",
    "# only consider the rename columns\n",
    "charge_events = charge_events[list(colmap.keys())]\n",
    "\n",
    "# actually rename the columns\n",
    "charge_events = charge_events.rename(columns=colmap)\n",
    "\n",
    "# filter for low duration and low charge amount\n",
    "charge_events = charge_events[~((charge_events.total_duration<1*60) | (charge_events.total_charge<50))]\n",
    "\n",
    "# transform dates from strings to pandas datetimes\n",
    "charge_events['starttime'] = pd.to_datetime(charge_events['starttime'], format=\"%d/%m/%Y %H:%M\")\n",
    "\n",
    "# simplify the identification of EVs\n",
    "charge_events['ev_id'] = charge_events['ev_id'].str.split('*').str[-1]\n",
    "\n",
    "# calculate the endtime using the duration\n",
    "charge_events['endtime'] = charge_events['starttime'] + pd.to_timedelta(charge_events['total_duration'], unit='s')\n",
    "\n",
    "# removing missing values\n",
    "charge_events = charge_events[charge_events['endtime'].notnull()]\n",
    "\n",
    "# transform Wh to kWh\n",
    "charge_events['total_charge'] = charge_events['total_charge'] / 1000\n",
    "\n",
    "# summary statistics after basic preparation of the data\n",
    "print(\"Summary statistics of the clean raw data\")\n",
    "charge_events.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Represent the charge event in 15 minutes intervals\n",
    "\n",
    "For example, a charge event that occured on the 2019-03-20 that starts at 13:05 and ends at 13:40 is divided in 3 sections:\n",
    "\n",
    "- `2019-03-20 13:05`-`2019-03-20 13:15` containing `10` minutes that belongs to the interval `2019-03-20 13:00`-`2019-03-20 13:15`\n",
    "- `2019-03-20 13:15`-`2019-03-20 13:30` containing `15` minutes that belongs to the interval `2019-03-20 13:15`-`2019-03-20 13:30`\n",
    "- `2019-03-20 13:30`-`2019-03-20 13:35` containing `5` minutes that belongs to the interval `2019-03-20 13:30`-`2019-03-20 13:45`\n",
    "\n",
    "In terms of nomenclature, the above sections fullfills the following template (replacing the values by variable names)\n",
    "\n",
    "`[start]`-`[end]` containing `[duration]` minutes that belongs to the interval `[inverval]` - `[interval + 15minutes]`\n",
    "\n",
    "Additionally: \n",
    "- `interval_time` refers to the starting time (`13:05`) of the interval without the date\n",
    "- `17h_day` corresponds to our day of interest (17h shift) according to our mail intervention. Given that we sent emails ath 16h, a day starts at 17h and ends at 17h of the next day.\n",
    "- `critical` will signal if the time falls into critical time (11:00 to 15:00)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T14:31:05.985933Z",
     "start_time": "2021-02-09T14:31:04.271381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2005, 10) (2005, 24) (247, 13)\n"
     ]
    }
   ],
   "source": [
    "# Split into quarters\n",
    "intervals = pd.DataFrame(((\n",
    "                        e.charge_id, \n",
    "                        # 17 hour day\n",
    "                        (date - pd.Timedelta(hours=17)).floor('1D'),\n",
    "                        date,\n",
    "                        e.starttime if date == e.starttime.floor('15min') else date,\n",
    "                        e.endtime if date == e.endtime.floor('15min') else date + pd.Timedelta(minutes=15),\n",
    "                        date == e.starttime.floor('15min')\n",
    "                    )    \n",
    "                    #iterate over thet uples\n",
    "                    for e  in charge_events.itertuples()\n",
    "                    # iterate for each range date\n",
    "                    for date in pd.date_range(e.starttime.floor('15min'), e.endtime.floor('15min'), freq='15min')\n",
    "                ), columns = ['charge_id', '17h_day','interval', 'start', 'end', 'charge_started'])\n",
    "\n",
    "# just the time of the interval\n",
    "intervals['interval_time'] = pd.to_timedelta(intervals['interval'].dt.time.astype(str))\n",
    "\n",
    "# is critical time\n",
    "intervals['critical'] = (intervals['interval_time'] >= pd.Timedelta('11:00:00')) & (intervals['interval_time'] < pd.Timedelta('15:00:00'))\n",
    "\n",
    "# leave it as string, because pandas don't store this appropiatedly as CSV\n",
    "intervals['interval_time'] = intervals['interval'].dt.time.astype(str)\n",
    "\n",
    "# calculate the duration\n",
    "intervals['duration'] = intervals['end']- intervals['start']\n",
    "\n",
    "# duration in seconds\n",
    "intervals['secs'] = intervals['duration'].dt.total_seconds()\n",
    "\n",
    "# merge back to includes the rest of the columns of clean data, e.g. client_id, starttime, endtime\n",
    "charge_events_15m = intervals.merge(charge_events, how='left', on='charge_id')\n",
    "\n",
    "# calculate the duration weight\n",
    "charge_events_15m['weight'] = charge_events_15m['duration'].dt.total_seconds() / charge_events_15m['total_duration']\n",
    "\n",
    "# calculate the charge\n",
    "charge_events_15m['charge'] = charge_events_15m['total_charge'] * charge_events_15m['weight']\n",
    "\n",
    "# select relevan columns for the rest of the analysis\n",
    "charge_clients_15m = charge_events_15m[[\n",
    "    'client_id', 'charge_id', 'ev_id', \n",
    "    'station_id', 'station', 'station_sn','station_st',\n",
    "    'charge_started',  'start', 'critical', 'end',  '17h_day', \n",
    "    'interval_time', 'interval', 'duration', 'secs', 'starttime', 'endtime', \n",
    "    'total_duration', 'total_charge', 'weight', 'charge']]\n",
    "\n",
    "# Final shapes\n",
    "print(intervals.shape, charge_events_15m.shape, charge_events.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T14:31:06.120442Z",
     "start_time": "2021-02-09T14:31:05.994954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the total charges between the datasets\n",
      "Passed. The total charge is the same.\n",
      "Comparing the duration per charge id between the datasets\n",
      "Passed. The durations per charge are the same.\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparing the total charges between the datasets\")\n",
    "if charge_events.total_charge.sum().round(8) == charge_events_15m.charge.sum().round(8):\n",
    "    print('Passed. The total charge is the same.')\n",
    "else:\n",
    "    print(f\"Total charge in source dataset: {charge_events.total_charge.sum()}\")\n",
    "    print(f\"Total charge in the 15-minutes interval dataset: {charge_events_15m.charge.sum()}\")\n",
    "    raise Exception('Something went wrong creation the 15-minutes dataset. ', \n",
    "                    'The total charges should be the same, yet they are not.')\n",
    "\n",
    "\n",
    "# Calculate the durations on the source dataset\n",
    "charge_events_indexed = charge_events.set_index('charge_id')\n",
    "totals = (charge_events_indexed['endtime'] - charge_events_indexed['starttime']).sort_index()\n",
    "\n",
    "# Calculate the durations in the 15-minutes interval dataset\n",
    "_15min_totals = charge_events_15m.groupby('charge_id')['duration'].sum().sort_index()\n",
    " \n",
    "print(\"Comparing the duration per charge id between the datasets\")\n",
    "if _15min_totals.equals(totals):\n",
    "    print('Passed. The durations per charge are the same.')\n",
    "else:\n",
    "    raise Exception('Something went wrong creation the 15-minutes dataset. ', \n",
    "                    'The durations per charge should be the same, yet they are not.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charges per client in 15 minutes intervals\n",
    "\n",
    "Similar to the charge event in 15 minutes intervals, but the unit used is clients insteadof the events. In 5 cases, doing this per charge id would produce inconsistencies in the representation of the data, because of consecutive charges during the same 15 minutes interval on the same quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T14:31:06.967246Z",
     "start_time": "2021-02-09T14:31:06.124909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the total charges between the datasets\n",
      "Passed. The total charge is the same.\n"
     ]
    }
   ],
   "source": [
    "# Copy the events dataframe\n",
    "charge_clients_15m = charge_events_15m.copy()\n",
    "\n",
    "# Two charge ids could fall into the same interval, so a new column (charge ids)\n",
    "# will hold this information\n",
    "charge_clients_15m['charge_ids'] = charge_clients_15m['charge_id']\n",
    "\n",
    "# Group the data by client_id and intervat. The rest of the columns in the groupby\n",
    "# operation are redundant but they are kept so that they appear in the resulting \n",
    "# dataframe (otherwise they should be merge back)\n",
    "charge_clients_15m = charge_clients_15m.groupby(\n",
    "    ['client_id', 'interval', '17h_day', 'interval_time', 'critical',\n",
    "      'station_id', 'station', 'station_sn','station_st']).agg({\n",
    "        # why max? check client_id = 7257, and interval_day = 2019-02-27\n",
    "        'charge_started': 'max', \n",
    "        'charge_id': 'max',\n",
    "        'charge_ids': lambda x: tuple(x),\n",
    "        'ev_id': lambda x: tuple(x),\n",
    "        'starttime': 'min',\n",
    "        'endtime': 'max',\n",
    "        'start': 'min',\n",
    "        'end': 'max',\n",
    "        'duration': 'sum',\n",
    "        'secs': 'sum',\n",
    "        'charge': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "# select relevant columns for the rest of the analysis\n",
    "charge_clients_15m = charge_clients_15m[[\n",
    "    'client_id', 'charge_id', 'charge_ids', 'ev_id', 'station_id', 'station_st', \n",
    "    'charge_started', 'start', 'critical', 'end', '17h_day', \n",
    "    'interval_time', 'interval', 'duration', 'secs', 'charge']]\n",
    " \n",
    "# Quick sanity check\n",
    "print(\"Comparing the total charges between the datasets\")\n",
    "if charge_clients_15m.charge.sum() == charge_clients_15m.charge.sum():\n",
    "    print('Passed. The total charge is the same.')\n",
    "else:\n",
    "    print(f\"Total charge in source dataset: {charge_clients_15m.total_charge.sum()}\")\n",
    "    print(f\"Total charge in the 15-minutes interval dataset: {charge_clients_15m.charge.sum()}\")\n",
    "    raise Exception('Something went wrong creation the 15-minutes dataset. ', \n",
    "                    'The total charges should be the same, yet they are not.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary statistics per charge event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T14:31:07.247257Z",
     "start_time": "2021-02-09T14:31:06.970973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients charging on maildays: 66\n",
      "Clients charging on non maildays: 53\n",
      "Charge events on maildays: 135\n",
      "Charge events on non maildays: 126\n",
      "\n",
      "Full summary\n",
      "           charges started               charge              kgCO2eq\n",
      "count               247.00               247.00               247.00\n",
      "mean                  1.00                10.22                 1.22\n",
      "std                   0.00                 8.62                 1.78\n",
      "min                   1.00                 0.13                 0.02\n",
      "25%                   1.00                 3.93                 0.32\n",
      "50%                   1.00                 7.02                 0.66\n",
      "75%                   1.00                15.26                 1.22\n",
      "max                   1.00                38.68                14.18\n",
      "Totals:\n",
      "charges started                 247.00\n",
      "charge                         2524.27\n",
      "kgCO2eq                         301.98\n",
      "dtype: float64\n",
      "\n",
      "Summary of Mail Days\n",
      "           charges started               charge              kgCO2eq\n",
      "count               135.00               135.00               135.00\n",
      "mean                  0.96                 9.67                 0.75\n",
      "std                   0.21                 7.58                 0.83\n",
      "min                   0.00                 0.13                 0.01\n",
      "25%                   1.00                 3.67                 0.24\n",
      "50%                   1.00                 7.25                 0.54\n",
      "75%                   1.00                15.03                 0.90\n",
      "max                   1.00                37.07                 5.95\n",
      "Totals:\n",
      "charges started                 129.00\n",
      "charge                         1304.97\n",
      "kgCO2eq                         100.75\n",
      "dtype: float64\n",
      "\n",
      "Full of Non Mail Days\n",
      "           charges started               charge              kgCO2eq\n",
      "count               126.00               126.00               126.00\n",
      "mean                  0.94                 9.68                 1.60\n",
      "std                   0.24                 9.20                 2.25\n",
      "min                   0.00                 0.14                 0.02\n",
      "25%                   1.00                 3.56                 0.35\n",
      "50%                   1.00                 6.54                 0.74\n",
      "75%                   1.00                11.25                 1.62\n",
      "max                   1.00                38.68                14.18\n",
      "Totals:\n",
      "charges started                 118.00\n",
      "charge                         1219.31\n",
      "kgCO2eq                         201.23\n",
      "dtype: float64\n",
      "\n",
      "Full summary (per day)\n",
      "           charges started               charge              kgCO2eq\n",
      "count                42.00                42.00                42.00\n",
      "mean                  5.88                60.10                 7.19\n",
      "std                   3.78                42.24                 6.58\n",
      "min                   1.00                 6.35                 0.25\n",
      "25%                   3.00                23.02                 1.87\n",
      "50%                   5.00                51.92                 6.39\n",
      "75%                   8.00                88.17                 9.72\n",
      "max                  18.00               159.10                29.92\n",
      "Totals:\n",
      "charges started                 247.00\n",
      "charge                         2524.27\n",
      "kgCO2eq                         301.98\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# merge with the energy emissions dataset\n",
    "_merged = charge_events_15m.merge(co2_emissions[['interval','kgCO2eq/kWh']], how='left', on='interval')\n",
    "\n",
    "# calculate kgCO2eq\n",
    "_merged['kgCO2eq'] = _merged['charge'] * _merged['kgCO2eq/kWh']\n",
    "\n",
    "# merge with the client mails information to identify those who where mailed\n",
    "_merged = _merged.merge(client_mails, how='left', on=['17h_day','client_id'])\n",
    "\n",
    "# identify the maildays\n",
    "_merged = _merged.merge(maildays, how='left', on='17h_day')\n",
    "\n",
    "# missings correspond to false for mailed\n",
    "_merged['mailed'] = _merged['mailed'].notnull() \n",
    "\n",
    "# missings correspond to false for mailday\n",
    "_merged['mailday'] = _merged['mailday'].notnull() \n",
    "\n",
    "_merged['charges started'] = _merged['charge_started'].astype(int)\n",
    "\n",
    "# display summary statistics\n",
    "print(f'Clients charging on maildays: {len(_merged[_merged.mailday].client_id.unique())}')\n",
    "print(f'Clients charging on non maildays: {len(_merged[~_merged.mailday].client_id.unique())}')\n",
    "print(f'Charge events on maildays: {len(_merged[_merged.mailday].charge_id.unique())}')\n",
    "print(f'Charge events on non maildays: {len(_merged[~_merged.mailday].charge_id.unique())}')\n",
    "\n",
    "print(\"\\nFull summary\")\n",
    "print(_merged.groupby(['charge_id']).agg({'charges started': 'sum', 'charge': 'sum', 'kgCO2eq': 'sum'}).describe())\n",
    "print(\"Totals:\")\n",
    "print(_merged[['charges started','charge', 'kgCO2eq']].sum())\n",
    "\n",
    "print(\"\\nSummary of Mail Days\")\n",
    "print(_merged[_merged.mailday].groupby(['charge_id']).agg({'charges started': 'sum', 'charge': 'sum', 'kgCO2eq': 'sum'}).describe())\n",
    "print(\"Totals:\")\n",
    "print(_merged[_merged.mailday][['charges started', 'charge', 'kgCO2eq']].sum())\n",
    "\n",
    "print(\"\\nFull of Non Mail Days\")\n",
    "print(_merged[~_merged.mailday].groupby(['charge_id']).agg({'charges started': 'sum', 'charge': 'sum', 'kgCO2eq': 'sum'}).describe())\n",
    "print(\"Totals:\")\n",
    "print(_merged[~_merged.mailday][['charges started', 'charge', 'kgCO2eq']].sum())\n",
    "\n",
    "print(\"\\nFull summary (per day)\")\n",
    "print(_merged.groupby(['17h_day']).agg({'charges started': 'sum', 'charge': 'sum', 'kgCO2eq': 'sum'}).describe())\n",
    "print(\"Totals:\")\n",
    "print(_merged[['charges started', 'charge', 'kgCO2eq']].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create main dataframe of analysis per client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T14:31:07.330795Z",
     "start_time": "2021-02-09T14:31:07.257857Z"
    }
   },
   "outputs": [],
   "source": [
    "# merge with the energy emissions dataset\n",
    "main_df = charge_clients_15m.merge(co2_emissions[['interval','kgCO2eq/kWh']], how='left', on='interval')\n",
    "\n",
    "# calculate kgCO2eq\n",
    "main_df['kgCO2eq'] = main_df['charge'] * main_df['kgCO2eq/kWh']\n",
    "\n",
    "# merge with the client mails information to identify those who where mailed\n",
    "main_df = main_df.merge(client_mails, how='left', on=['17h_day','client_id'])\n",
    "\n",
    "# identify the maildays\n",
    "main_df = main_df.merge(maildays, how='left', on='17h_day')\n",
    "\n",
    "# missings correspond to false for mailed\n",
    "main_df['mailed'] = main_df['mailed'].notnull() \n",
    "\n",
    "# missings correspond to false for mailday\n",
    "main_df['mailday'] = main_df['mailday'].notnull() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Summary statistics per charge event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T14:31:07.589021Z",
     "start_time": "2021-02-09T14:31:07.335206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full summary\n",
      "            charge_started               charge              kgCO2eq\n",
      "count                90.00                90.00                90.00\n",
      "mean                  2.74                28.05                 3.36\n",
      "std                   2.58                41.16                 6.05\n",
      "min                   1.00                 0.57                 0.04\n",
      "25%                   1.00                 5.94                 0.57\n",
      "50%                   2.00                17.24                 1.36\n",
      "75%                   3.00                33.02                 3.08\n",
      "max                  13.00               316.42                44.23\n",
      "Totals:\n",
      "charge_started                 247.00\n",
      "charge                        2524.27\n",
      "kgCO2eq                        301.98\n",
      "dtype: float64\n",
      "\n",
      "Summary of Mail Days\n",
      "            charge_started               charge              kgCO2eq\n",
      "count                66.00                66.00                66.00\n",
      "mean                  1.95                19.77                 1.53\n",
      "std                   1.66                22.70                 1.86\n",
      "min                   0.00                 0.55                 0.04\n",
      "25%                   1.00                 5.66                 0.39\n",
      "50%                   1.00                11.55                 0.93\n",
      "75%                   2.00                24.78                 1.58\n",
      "max                   9.00               107.11                10.15\n",
      "Totals:\n",
      "charge_started                 129.00\n",
      "charge                        1304.97\n",
      "kgCO2eq                        100.75\n",
      "dtype: float64\n",
      "\n",
      "Full of Non Mail Days\n",
      "            charge_started               charge              kgCO2eq\n",
      "count                53.00                53.00                53.00\n",
      "mean                  2.23                23.01                 3.80\n",
      "std                   1.99                36.52                 6.54\n",
      "min                   0.00                 0.57                 0.07\n",
      "25%                   1.00                 5.05                 0.47\n",
      "50%                   1.00                12.45                 1.64\n",
      "75%                   3.00                28.25                 4.52\n",
      "max                   9.00               245.49                39.08\n",
      "Totals:\n",
      "charge_started                 118.00\n",
      "charge                        1219.31\n",
      "kgCO2eq                        201.23\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>charge_id</th>\n",
       "      <th>charge_ids</th>\n",
       "      <th>ev_id</th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_st</th>\n",
       "      <th>charge_started</th>\n",
       "      <th>start</th>\n",
       "      <th>critical</th>\n",
       "      <th>end</th>\n",
       "      <th>17h_day</th>\n",
       "      <th>interval_time</th>\n",
       "      <th>interval</th>\n",
       "      <th>duration</th>\n",
       "      <th>secs</th>\n",
       "      <th>charge</th>\n",
       "      <th>kgCO2eq/kWh</th>\n",
       "      <th>kgCO2eq</th>\n",
       "      <th>mailed</th>\n",
       "      <th>mailday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7005</td>\n",
       "      <td>105</td>\n",
       "      <td>(105,)</td>\n",
       "      <td>(E1000311,)</td>\n",
       "      <td>20818</td>\n",
       "      <td>Bahnhofsplatz 1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-03-19 15:06:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-03-19 15:15:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>2019-03-19 15:00:00</td>\n",
       "      <td>00:09:00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.49</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7005</td>\n",
       "      <td>105</td>\n",
       "      <td>(105,)</td>\n",
       "      <td>(E1000311,)</td>\n",
       "      <td>20818</td>\n",
       "      <td>Bahnhofsplatz 1</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-03-19 15:15:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-03-19 15:16:54</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>15:15:00</td>\n",
       "      <td>2019-03-19 15:15:00</td>\n",
       "      <td>00:01:54</td>\n",
       "      <td>114.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7009</td>\n",
       "      <td>257</td>\n",
       "      <td>(257,)</td>\n",
       "      <td>(E1000119,)</td>\n",
       "      <td>924</td>\n",
       "      <td>Hintermarkt-Parkplatz</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-02-11 19:45:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-02-11 20:00:00</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>19:45:00</td>\n",
       "      <td>2019-02-11 19:45:00</td>\n",
       "      <td>00:15:00</td>\n",
       "      <td>900.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7009</td>\n",
       "      <td>257</td>\n",
       "      <td>(257,)</td>\n",
       "      <td>(E1000119,)</td>\n",
       "      <td>924</td>\n",
       "      <td>Hintermarkt-Parkplatz</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-02-11 20:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-02-11 20:15:00</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>2019-02-11 20:00:00</td>\n",
       "      <td>00:15:00</td>\n",
       "      <td>900.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7009</td>\n",
       "      <td>257</td>\n",
       "      <td>(257,)</td>\n",
       "      <td>(E1000119,)</td>\n",
       "      <td>924</td>\n",
       "      <td>Hintermarkt-Parkplatz</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-02-11 20:15:00</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-02-11 20:30:00</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>20:15:00</td>\n",
       "      <td>2019-02-11 20:15:00</td>\n",
       "      <td>00:15:00</td>\n",
       "      <td>900.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7317</td>\n",
       "      <td>21</td>\n",
       "      <td>(21,)</td>\n",
       "      <td>(E1000546,)</td>\n",
       "      <td>20697</td>\n",
       "      <td>Friedenstraße 2</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-03-17 12:15:00</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-03-17 12:30:00</td>\n",
       "      <td>2019-03-16</td>\n",
       "      <td>12:15:00</td>\n",
       "      <td>2019-03-17 12:15:00</td>\n",
       "      <td>00:15:00</td>\n",
       "      <td>900.00</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>7317</td>\n",
       "      <td>21</td>\n",
       "      <td>(21,)</td>\n",
       "      <td>(E1000546,)</td>\n",
       "      <td>20697</td>\n",
       "      <td>Friedenstraße 2</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-03-17 12:30:00</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-03-17 12:45:00</td>\n",
       "      <td>2019-03-16</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>2019-03-17 12:30:00</td>\n",
       "      <td>00:15:00</td>\n",
       "      <td>900.00</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>7317</td>\n",
       "      <td>21</td>\n",
       "      <td>(21,)</td>\n",
       "      <td>(E1000546,)</td>\n",
       "      <td>20697</td>\n",
       "      <td>Friedenstraße 2</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-03-17 12:45:00</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-03-17 13:00:00</td>\n",
       "      <td>2019-03-16</td>\n",
       "      <td>12:45:00</td>\n",
       "      <td>2019-03-17 12:45:00</td>\n",
       "      <td>00:15:00</td>\n",
       "      <td>900.00</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>7317</td>\n",
       "      <td>21</td>\n",
       "      <td>(21,)</td>\n",
       "      <td>(E1000546,)</td>\n",
       "      <td>20697</td>\n",
       "      <td>Friedenstraße 2</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-03-17 13:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-03-17 13:15:00</td>\n",
       "      <td>2019-03-16</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>2019-03-17 13:00:00</td>\n",
       "      <td>00:15:00</td>\n",
       "      <td>900.00</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>7317</td>\n",
       "      <td>21</td>\n",
       "      <td>(21,)</td>\n",
       "      <td>(E1000546,)</td>\n",
       "      <td>20697</td>\n",
       "      <td>Friedenstraße 2</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-03-17 13:15:00</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-03-17 13:21:02</td>\n",
       "      <td>2019-03-16</td>\n",
       "      <td>13:15:00</td>\n",
       "      <td>2019-03-17 13:15:00</td>\n",
       "      <td>00:06:02</td>\n",
       "      <td>362.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      client_id  charge_id charge_ids        ev_id  station_id  \\\n",
       "0          7005        105     (105,)  (E1000311,)       20818   \n",
       "1          7005        105     (105,)  (E1000311,)       20818   \n",
       "2          7009        257     (257,)  (E1000119,)         924   \n",
       "3          7009        257     (257,)  (E1000119,)         924   \n",
       "4          7009        257     (257,)  (E1000119,)         924   \n",
       "...         ...        ...        ...          ...         ...   \n",
       "1995       7317         21      (21,)  (E1000546,)       20697   \n",
       "1996       7317         21      (21,)  (E1000546,)       20697   \n",
       "1997       7317         21      (21,)  (E1000546,)       20697   \n",
       "1998       7317         21      (21,)  (E1000546,)       20697   \n",
       "1999       7317         21      (21,)  (E1000546,)       20697   \n",
       "\n",
       "                 station_st  charge_started               start  critical  \\\n",
       "0           Bahnhofsplatz 1            True 2019-03-19 15:06:00     False   \n",
       "1           Bahnhofsplatz 1           False 2019-03-19 15:15:00     False   \n",
       "2     Hintermarkt-Parkplatz            True 2019-02-11 19:45:00     False   \n",
       "3     Hintermarkt-Parkplatz           False 2019-02-11 20:00:00     False   \n",
       "4     Hintermarkt-Parkplatz           False 2019-02-11 20:15:00     False   \n",
       "...                     ...             ...                 ...       ...   \n",
       "1995        Friedenstraße 2           False 2019-03-17 12:15:00      True   \n",
       "1996        Friedenstraße 2           False 2019-03-17 12:30:00      True   \n",
       "1997        Friedenstraße 2           False 2019-03-17 12:45:00      True   \n",
       "1998        Friedenstraße 2           False 2019-03-17 13:00:00      True   \n",
       "1999        Friedenstraße 2           False 2019-03-17 13:15:00      True   \n",
       "\n",
       "                     end    17h_day interval_time            interval  \\\n",
       "0    2019-03-19 15:15:00 2019-03-18      15:00:00 2019-03-19 15:00:00   \n",
       "1    2019-03-19 15:16:54 2019-03-18      15:15:00 2019-03-19 15:15:00   \n",
       "2    2019-02-11 20:00:00 2019-02-11      19:45:00 2019-02-11 19:45:00   \n",
       "3    2019-02-11 20:15:00 2019-02-11      20:00:00 2019-02-11 20:00:00   \n",
       "4    2019-02-11 20:30:00 2019-02-11      20:15:00 2019-02-11 20:15:00   \n",
       "...                  ...        ...           ...                 ...   \n",
       "1995 2019-03-17 12:30:00 2019-03-16      12:15:00 2019-03-17 12:15:00   \n",
       "1996 2019-03-17 12:45:00 2019-03-16      12:30:00 2019-03-17 12:30:00   \n",
       "1997 2019-03-17 13:00:00 2019-03-16      12:45:00 2019-03-17 12:45:00   \n",
       "1998 2019-03-17 13:15:00 2019-03-16      13:00:00 2019-03-17 13:00:00   \n",
       "1999 2019-03-17 13:21:02 2019-03-16      13:15:00 2019-03-17 13:15:00   \n",
       "\n",
       "     duration                 secs               charge          kgCO2eq/kWh  \\\n",
       "0    00:09:00               540.00                 2.67                 0.18   \n",
       "1    00:01:54               114.00                 0.56                 0.19   \n",
       "2    00:15:00               900.00                 0.33                 0.13   \n",
       "3    00:15:00               900.00                 0.33                 0.16   \n",
       "4    00:15:00               900.00                 0.33                 0.16   \n",
       "...       ...                  ...                  ...                  ...   \n",
       "1995 00:15:00               900.00                 1.29                 0.03   \n",
       "1996 00:15:00               900.00                 1.29                 0.03   \n",
       "1997 00:15:00               900.00                 1.29                 0.03   \n",
       "1998 00:15:00               900.00                 1.29                 0.03   \n",
       "1999 00:06:02               362.00                 0.52                 0.03   \n",
       "\n",
       "                  kgCO2eq  mailed  mailday  \n",
       "0                    0.49   False    False  \n",
       "1                    0.11   False    False  \n",
       "2                    0.04   False    False  \n",
       "3                    0.05   False    False  \n",
       "4                    0.05   False    False  \n",
       "...                   ...     ...      ...  \n",
       "1995                 0.04    True     True  \n",
       "1996                 0.04    True     True  \n",
       "1997                 0.04    True     True  \n",
       "1998                 0.04    True     True  \n",
       "1999                 0.02    True     True  \n",
       "\n",
       "[2000 rows x 20 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['charges started'] = main_df['charge_started'].astype(int)\n",
    "\n",
    "print(\"\\nFull summary\")\n",
    "print(main_df.groupby(['client_id']).agg({'charge_started': 'sum', 'charge': 'sum', 'kgCO2eq': 'sum'}).describe())\n",
    "print(\"Totals:\")\n",
    "print(main_df[['charge_started', 'charge', 'kgCO2eq']].sum())\n",
    "\n",
    "print(\"\\nSummary of Mail Days\")\n",
    "print(main_df[main_df.mailday].groupby(['client_id']).agg({'charge_started': 'sum', 'charge': 'sum', 'kgCO2eq': 'sum'}).describe())\n",
    "print(\"Totals:\")\n",
    "print(main_df[main_df.mailday][['charge_started', 'charge', 'kgCO2eq']].sum())\n",
    "\n",
    "print(\"\\nFull of Non Mail Days\")\n",
    "print(main_df[~main_df.mailday].groupby(['client_id']).agg({'charge_started': 'sum', 'charge': 'sum', 'kgCO2eq': 'sum'}).describe())\n",
    "print(\"Totals:\")\n",
    "print(main_df[~main_df.mailday][['charge_started', 'charge', 'kgCO2eq']].sum())\n",
    "\n",
    "main_df.drop(columns = ['charges started'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataset version for visualization and statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compact dataset with critical vs non critical information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T14:31:07.637740Z",
     "start_time": "2021-02-09T14:31:07.591799Z"
    }
   },
   "outputs": [],
   "source": [
    "# columns of interests \n",
    "coi = ['client_id', 'charge_id', 'station_id', 'critical', 'charge_started', \n",
    "       '17h_day', 'interval_time', 'charge', 'kgCO2eq','secs']\n",
    "\n",
    "# aggregate according to clients, days and critical\n",
    "critical_df = main_df[coi].groupby(['client_id', '17h_day', 'critical']).agg({\n",
    "    'charge_id': lambda x: set(x),\n",
    "    'station_id': lambda x: set(x),\n",
    "    'charge_started': 'any',\n",
    "    'charge': 'sum',\n",
    "    'kgCO2eq': 'sum',\n",
    "    'secs': 'sum'\n",
    "})\n",
    "\n",
    "# store as a pickle to keep pandas data types\n",
    "critical_df.to_pickle('output/critical.pickle')\n",
    "\n",
    "# alternatively, export it as CSV\n",
    "#critical_df.to_csv('output/critical.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long format dataset containing critical times when no charges occured\n",
    "\n",
    "This representation of the data accounts for the times in which the clients did not charge (the zeros rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T14:31:10.272085Z",
     "start_time": "2021-02-09T14:31:07.642239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26712, 3)\n",
      "(26712, 4)\n",
      "(26712, 11)\n",
      "(26712, 12)\n"
     ]
    }
   ],
   "source": [
    "# create a skeleton for the long format representation\n",
    "ldf = pd.DataFrame(((x, y, z) \n",
    "                    for x in codes \n",
    "                    for y in pd.date_range(main_df['17h_day'].min(), main_df['17h_day'].max(), freq='1D') \n",
    "                    for z in (False, True)),\n",
    "                   columns=('client_id', '17h_day', 'critical'))\n",
    "print(ldf.shape)\n",
    "\n",
    "# tag maildays in the dataset\n",
    "ldf = ldf.merge(main_df[['17h_day', 'mailday']].drop_duplicates(), how='left', on='17h_day')\n",
    "print(ldf.shape)\n",
    "\n",
    "# merge with the critical dataframe\n",
    "ldf = ldf.merge(critical_df.reset_index(), how='left', on=(\n",
    "    'client_id', '17h_day', 'critical'), indicator=True)\n",
    "print(ldf.shape)\n",
    "\n",
    "ldf = ldf.merge(client_mails, how='left', on=['17h_day', 'client_id'])\n",
    "print(ldf.shape)\n",
    "    \n",
    "#ldf = ldf.merge(critical_df.reset_index(), how='left', on=('client_id', '17h_day', 'critical'), indicator=True)\n",
    "ldf[['mailed', 'mailday', 'charge_started']] = ldf[['mailed', 'mailday', 'charge_started']].fillna(False).astype(bool)\n",
    "\n",
    "# assign right types to columns\n",
    "ldf['charge'] = ldf['charge'].fillna(0)\n",
    "\n",
    "#ldf[['weight', 'charge', 'kgCO2eq']] = ldf[['weight', 'charge', 'kgCO2eq']].fillna(0)\n",
    "# weekends go from Friday 17h to Sunday 17h, after the 17h shift, this means \n",
    "# Fridays and Saturdays corresponds to weekends\n",
    "ldf['is_weekday'] = ~((ldf['17h_day'].dt.weekday == 4) | \n",
    "                     (ldf['17h_day'].dt.weekday == 5) | \n",
    "                     (ldf['17h_day'] == '2019-03-03'))\n",
    "\n",
    "\n",
    "# save this as a Python pickle to not loss data types\n",
    "ldf.to_pickle('output/critical_long_format.pickle')\n",
    "\n",
    "# or export as CSV\n",
    "# ldf.to_csv('output/50-critical_long_format.csv', index=False)\n",
    "ldf.to_csv('output/critical_long_format.csv', index=False)\n",
    "\n",
    "# Add a dummy to all conditions statistical analysis purposes\n",
    "dummies = []\n",
    "for x,g in ldf.groupby(['is_weekday', 'mailday', 'critical', 'mailed']):\n",
    "    dummies.append((*x,1,1/3600,1,1))\n",
    "dfdummy = pd.DataFrame(dummies, columns=[\n",
    "    'is_weekday', 'mailday', 'critical', 'mailed', \n",
    "    'charge', 'hours', 'kgCO2eq', 'charge_started' ])\n",
    "ldf_dummy = pd.concat([ldf,dfdummy])\n",
    "\n",
    "# code booleans as binaries\n",
    "ldf_dummy[ldf_dummy.select_dtypes('boolean').columns] = ldf_dummy.select_dtypes('boolean').astype(int)\n",
    "ldf[ldf.select_dtypes('boolean').columns] = ldf.select_dtypes('boolean').astype(int)\n",
    "\n",
    "# code missing charges as 0s\n",
    "ldf_dummy['charge'] = ldf_dummy['charge'].fillna(0)\n",
    "ldf['charge'] = ldf['charge'].fillna(0)\n",
    "\n",
    "# save to csv (so it is compatible with R)\n",
    "ldf_dummy.to_csv('output/critical_long_format_with_dummy.csv', index=False)\n",
    "ldf.to_csv('output/critical_long_format.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T10:30:37.562169Z",
     "start_time": "2020-10-10T10:30:37.365932Z"
    }
   },
   "source": [
    "## Long format dataset containing information about charges in 15 minutes interval regardles if there where or not charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T14:31:23.789865Z",
     "start_time": "2021-02-09T14:31:10.283798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1239564, 3)\n",
      "(1239564, 4)\n",
      "(1239564, 5)\n",
      "(1239564, 8)\n"
     ]
    }
   ],
   "source": [
    "# create a skeleton for the 15minutes long format representation\n",
    "uldf = pd.DataFrame(((client, interval) \n",
    "                    for client in codes \n",
    "                    for interval in pd.date_range(main_df.interval.min(), main_df.interval.max(), freq='15min')),\n",
    "                   columns=('client_id', 'interval'))\n",
    "\n",
    "# calculate the day\n",
    "#uldf['interval_day'] = pd.to_datetime(uldf.interval.dt.date)\n",
    "uldf['17h_day'] = pd.to_datetime((uldf.interval - pd.Timedelta(hours=17)).dt.date)\n",
    "\n",
    "print(uldf.shape)\n",
    "\n",
    "# # merge with maildays\n",
    "uldf = uldf.merge(maildays, how='left', on='17h_day')\n",
    "print(uldf.shape)\n",
    "\n",
    "# merge with the client mails\n",
    "uldf = uldf.merge(client_mails, how='left', on=['17h_day', 'client_id'])\n",
    "print(uldf.shape)\n",
    "      \n",
    "# merge with charges of clients\n",
    "uldf = uldf.merge(main_df[['client_id', 'interval', 'charge', 'kgCO2eq']], \n",
    "                  how='left', on=['client_id', 'interval'], indicator=True)\n",
    "print(uldf.shape)\n",
    "      \n",
    "# # mark weekdays\n",
    "uldf['is_weekday'] = ~((uldf['17h_day'].dt.weekday == 4) | \n",
    "                      (uldf['17h_day'].dt.weekday == 5) | \n",
    "                      (uldf['17h_day'] == '2019-03-03'))\n",
    "\n",
    "# assign right types to columns\n",
    "uldf['mailed'] = uldf['mailed'].fillna(False).astype(bool)\n",
    "uldf['mailday'] = uldf['mailday'].fillna(False).astype(bool)\n",
    "uldf['interval_time'] = uldf['interval'].dt.time\n",
    "\n",
    "# fill missings with zeros\n",
    "uldf['charge'] = uldf['charge'].fillna(0)\n",
    "uldf['kgCO2eq'] = uldf['kgCO2eq'].fillna(0)\n",
    "                                         \n",
    "# flag to indicate if there is charging happening\n",
    "uldf['charging'] = uldf['charge'] > 0\n",
    "\n",
    "# Adding co2/kwh\n",
    "uldf = uldf.merge(co2_emissions[['interval','kgCO2eq/kWh']], how='left', on='interval')\n",
    "\n",
    "# Store as pickle\n",
    "uldf.to_pickle('output/critical_15min_long_format.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
